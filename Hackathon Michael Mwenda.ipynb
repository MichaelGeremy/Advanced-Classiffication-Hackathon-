{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7023fc8",
   "metadata": {},
   "source": [
    "# EXPLORE Data Science Academy Classification Hackathon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b76574",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692bc0fb",
   "metadata": {},
   "source": [
    "South Africa is a multicultural society that is characterised by its rich linguistic diversity. Language is an indispensable tool that can be used to deepen democracy and also contribute to the social, cultural, intellectual, economic and political life of the South African society. With such a multilingual population, it is only obvious that our systems and devices also communicate in multi-languages.\n",
    "In this challenge, you will take text which is in any of South Africa's 11 Official languages and identify which language the text is in.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a07d425",
   "metadata": {},
   "source": [
    "## 1.1 Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015f7e2a",
   "metadata": {},
   "source": [
    "The task is to develop a machine learning model to identify language within a text, among the South Africa's 11 official languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d8a44c",
   "metadata": {},
   "source": [
    "## 2. Import Python Libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67867901",
   "metadata": {},
   "source": [
    "Let's import everything we need to begin. This will include techniques for text feature extraction and ways to divide our data. The models we want to train will be included in the subsequent sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b94c24f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import time\n",
    "\n",
    "# Explore Data Analysis\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.pyplot import rcParams\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# Data Preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.utils import resample\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "#NLTK (Natural Language Tool Kit) \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f6e01e",
   "metadata": {},
   "source": [
    "## 2.1 Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d43b337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train & test data sets\n",
    "train_df = pd.read_csv('train_set.csv')\n",
    "test_df = pd.read_csv('test_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9445a99e",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f182541a",
   "metadata": {},
   "source": [
    "This section aims to conduct initial investigation on the dataset, to identify patterns, anomalies, and suggestive hypotheses of the dataset. Among other features explored are infomation and shape on both train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9e75b333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the first 5 rows of train_df\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4554b495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                      Winste op buitelandse valuta."
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#viewing the first 5 rows of test_df\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "970f1a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33000 entries, 0 to 32999\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   lang_id  33000 non-null  object\n",
      " 1   text     33000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 515.8+ KB\n",
      "None\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5682 entries, 0 to 5681\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   index   5682 non-null   int64 \n",
      " 1   text    5682 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 88.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train_df.info()) #checking the data type of each column in the train data\n",
    "print('\\n')\n",
    "print(test_df.info()) #checking the data type of each column in the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6701dab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lang_id</th>\n",
       "      <td>33000</td>\n",
       "      <td>11</td>\n",
       "      <td>xho</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>33000</td>\n",
       "      <td>29948</td>\n",
       "      <td>ngokwesekhtjheni yomthetho ophathelene nalokhu...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count unique                                                top  freq\n",
       "lang_id  33000     11                                                xho  3000\n",
       "text     33000  29948  ngokwesekhtjheni yomthetho ophathelene nalokhu...    17"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display of the data statistics using the transpose method\n",
    "train_df.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e4282019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>5682.0</td>\n",
       "      <td>2841.5</td>\n",
       "      <td>1640.396446</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1421.25</td>\n",
       "      <td>2841.5</td>\n",
       "      <td>4261.75</td>\n",
       "      <td>5682.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count    mean          std  min      25%     50%      75%     max\n",
       "index  5682.0  2841.5  1640.396446  1.0  1421.25  2841.5  4261.75  5682.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "705bad4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for test data missing values \n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7f062eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang_id    0\n",
       "text       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for train data missing values \n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "94016604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>xho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>xho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text lang_id\n",
       "0  umgaqo-siseko wenza amalungiselelo kumaziko ax...     xho\n",
       "1  i-dha iya kuba nobulumko bokubeka umsebenzi na...     xho\n",
       "2  the province of kwazulu-natal department of tr...     eng"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang = train_df['text']\n",
    "\n",
    "# Creating a dataframe from the text column\n",
    "lang_df = pd.DataFrame(lang)\n",
    "\n",
    "# Add sentiment column to the language dataframe\n",
    "lang_df['lang_id'] = train_df['lang_id']\n",
    "\n",
    "# View the top 3 rows of languages\n",
    "lang_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55674b7",
   "metadata": {},
   "source": [
    "## 4. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bce45b",
   "metadata": {},
   "source": [
    "To process the data, a function cleaner is initialized, whose main purpose is;\n",
    "        1. Convet the text into lower case\n",
    "        2. Remove URLS,Hashtags(if any),Numeric Values, and Character Notes \n",
    "        3. Strip pucntuations and special characters\n",
    "        4. Remove white spaces and RTs (if any)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0bd23652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(texter):\n",
    "    \"\"\"\n",
    "    this function takes in a dataframe and perform the following:\n",
    "    -Convert letters to lowercases\n",
    "    -remove URL links\n",
    "    -remove # from hashtags\n",
    "    -remove numbers\n",
    "    -remove punctuation\n",
    "    from the text field then return a clean dataframe \n",
    "    \"\"\"\n",
    "    texter = texter.lower() #convert to text to lowercase\n",
    "    to_remove = [\n",
    "        r\"@[\\w]*\",  # strip account mentions\n",
    "        r\"http(s?):\\/\\/.*\\/\\w*\",  # strip URLs\n",
    "        r\"#\\w*\",  # strip hashtags\n",
    "        r\"\\d+\",  # delete numeric values\n",
    "        r\"U+FFFD\",  # remove the \"character note present\" diamond\n",
    "    ]\n",
    "    for key in to_remove:\n",
    "        texter = re.sub(key, \"\", texter)\n",
    "    \n",
    "    # strip punctuation and special characters\n",
    "    texter = re.sub(r\"[,.;':@#?!\\&/$]+\\ *\", \" \", texter)\n",
    "    \n",
    "    # strip excess white-space\n",
    "    texter = re.sub(r\"\\s\\s+\", \" \", texter)\n",
    "    texter = re.sub(r'rt[\\s]+', '', texter) #Remove RT\n",
    "    \n",
    "    return texter.lstrip(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d617b651",
   "metadata": {},
   "source": [
    "Now let us apply the cleaner fuction to both train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5ee99010",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply function to remove noise in the data\n",
    "train_df['text'] = train_df['text'].apply(cleaner)  \n",
    "test_df['text'] = test_df['text'].apply(cleaner)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c9e06b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32995</th>\n",
       "      <td>tsn</td>\n",
       "      <td>popo ya dipolateforomo tse ke go tlisa boetele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32996</th>\n",
       "      <td>sot</td>\n",
       "      <td>modise mosadi na o ntse o sa utlwe hore thaban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32997</th>\n",
       "      <td>eng</td>\n",
       "      <td>closing date for the submission of completed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32998</th>\n",
       "      <td>xho</td>\n",
       "      <td>nawuphina umntu ofunyenwe enetyala phantsi kwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32999</th>\n",
       "      <td>sot</td>\n",
       "      <td>mafapha a mang le ona a lokela ho etsa ditlale...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lang_id                                               text\n",
       "32995     tsn  popo ya dipolateforomo tse ke go tlisa boetele...\n",
       "32996     sot  modise mosadi na o ntse o sa utlwe hore thaban...\n",
       "32997     eng  closing date for the submission of completed t...\n",
       "32998     xho  nawuphina umntu ofunyenwe enetyala phantsi kwa...\n",
       "32999     sot  mafapha a mang le ona a lokela ho etsa ditlale..."
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b6d259",
   "metadata": {},
   "source": [
    "Assigning X and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4f0522c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y=train_df['lang_id']\n",
    "X=train_df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647fa326",
   "metadata": {},
   "source": [
    "## 4. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928366ba",
   "metadata": {},
   "source": [
    "We will specify the model names and invoke the classes that implement the model. Keep in mind that some of the classifiers require input variables. These are some instances of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f8daf99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering and Model Building\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from textblob import TextBlob\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f63abe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8dc89c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline1 = Pipeline([\n",
    "    ('bow',CountVectorizer(stop_words='english', \n",
    "                             min_df=2, \n",
    "                             max_df=0.5, \n",
    "                             ngram_range=(1, 1))),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "58e09ba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       986\n",
      "         eng       1.00      1.00      1.00       994\n",
      "         nbl       1.00      0.99      1.00       955\n",
      "         nso       1.00      1.00      1.00      1025\n",
      "         sot       1.00      1.00      1.00      1023\n",
      "         ssw       1.00      1.00      1.00       998\n",
      "         tsn       1.00      1.00      1.00       983\n",
      "         tso       1.00      1.00      1.00       952\n",
      "         ven       1.00      1.00      1.00      1034\n",
      "         xho       1.00      1.00      1.00      1004\n",
      "         zul       0.99      1.00      1.00       936\n",
      "\n",
      "    accuracy                           1.00     10890\n",
      "   macro avg       1.00      1.00      1.00     10890\n",
      "weighted avg       1.00      1.00      1.00     10890\n",
      "\n",
      "[[ 984    0    1    0    0    0    1    0    0    0    0]\n",
      " [   0  991    1    0    0    0    0    0    0    0    2]\n",
      " [   0    0  950    0    0    0    0    0    0    2    3]\n",
      " [   0    0    0 1025    0    0    0    0    0    0    0]\n",
      " [   0    0    0    1 1022    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0  998    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0  983    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0  952    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0 1034    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0 1003    1]\n",
      " [   0    0    1    0    0    0    0    0    0    2  933]]\n",
      "0.9986225895316805\n"
     ]
    }
   ],
   "source": [
    "pipeline1.fit(X_train,y_train)\n",
    "predictions = pipeline1.predict(X_test)\n",
    "print(classification_report(predictions,y_test))\n",
    "print(confusion_matrix(predictions,y_test))\n",
    "print(accuracy_score(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "49bde33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.591866</td>\n",
       "      <td>0.471963</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.464393</td>\n",
       "      <td>0.271945</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.519857</td>\n",
       "      <td>0.343980</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.015833</td>\n",
       "      <td>0.199982</td>\n",
       "      <td>0.999095</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.615862</td>\n",
       "      <td>0.199962</td>\n",
       "      <td>0.998643</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  1.591866    0.471963    0.998869          1.0\n",
       "1  1.464393    0.271945    0.998869          1.0\n",
       "2  1.519857    0.343980    0.999548          1.0\n",
       "3  2.015833    0.199982    0.999095          1.0\n",
       "4  1.615862    0.199962    0.998643          1.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn. model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "pipe_nb = make_pipeline(\n",
    "    CountVectorizer(),\n",
    "    MultinomialNB(alpha=0.006)\n",
    ")\n",
    "scores = cross_validate(pipe_nb, X_train, y_train, return_train_score=True)\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bd6cf14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Mike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Mike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.240282</td>\n",
       "      <td>0.279974</td>\n",
       "      <td>0.992990</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.071507</td>\n",
       "      <td>0.271970</td>\n",
       "      <td>0.996834</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.201093</td>\n",
       "      <td>0.288005</td>\n",
       "      <td>0.995025</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.295636</td>\n",
       "      <td>0.311972</td>\n",
       "      <td>0.993894</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.527701</td>\n",
       "      <td>0.279975</td>\n",
       "      <td>0.993894</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_score  train_score\n",
       "0  34.240282    0.279974    0.992990          1.0\n",
       "1  37.071507    0.271970    0.996834          1.0\n",
       "2  34.201093    0.288005    0.995025          1.0\n",
       "3  34.295636    0.311972    0.993894          1.0\n",
       "4  34.527701    0.279975    0.993894          1.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_nb2 = make_pipeline(\n",
    "    CountVectorizer(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "scores = cross_validate(pipe_nb2, X_train, y_train, return_train_score=True)\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0c5b471f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Mike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Mike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.824829</td>\n",
       "      <td>0.287993</td>\n",
       "      <td>0.992990</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.456189</td>\n",
       "      <td>0.343990</td>\n",
       "      <td>0.996834</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.921337</td>\n",
       "      <td>0.255979</td>\n",
       "      <td>0.995025</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.856634</td>\n",
       "      <td>0.287973</td>\n",
       "      <td>0.993894</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.767986</td>\n",
       "      <td>0.279969</td>\n",
       "      <td>0.993894</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_score  train_score\n",
       "0  35.824829    0.287993    0.992990          1.0\n",
       "1  32.456189    0.343990    0.996834          1.0\n",
       "2  32.921337    0.255979    0.995025          1.0\n",
       "3  34.856634    0.287973    0.993894          1.0\n",
       "4  34.767986    0.279969    0.993894          1.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_nb3 = make_pipeline(\n",
    "    CountVectorizer(),\n",
    "    SVC(C = 50, degree = 1, gamma = \"auto\", kernel = \"rbf\", probability = True)\n",
    ")\n",
    "scores = cross_validate(pipe_nb2, X_train, y_train, return_train_score=True)\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "afa23f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Mike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Mike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.489657</td>\n",
       "      <td>0.263992</td>\n",
       "      <td>0.992990</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.800047</td>\n",
       "      <td>0.383980</td>\n",
       "      <td>0.996834</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.926783</td>\n",
       "      <td>0.264207</td>\n",
       "      <td>0.995025</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.135484</td>\n",
       "      <td>0.391966</td>\n",
       "      <td>0.993894</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.680167</td>\n",
       "      <td>0.343970</td>\n",
       "      <td>0.993894</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_score  train_score\n",
       "0  37.489657    0.263992    0.992990          1.0\n",
       "1  35.800047    0.383980    0.996834          1.0\n",
       "2  36.926783    0.264207    0.995025          1.0\n",
       "3  37.135484    0.391966    0.993894          1.0\n",
       "4  35.680167    0.343970    0.993894          1.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_nb4 = make_pipeline(\n",
    "    CountVectorizer(),\n",
    "    RandomForestClassifier(n_estimators = 500, criterion = \"gini\", max_depth = 10,\n",
    "                                     max_features = \"auto\", min_samples_leaf = 0.005,\n",
    "                                     min_samples_split = 0.005, n_jobs = -1, random_state = 1000)\n",
    ")\n",
    "scores = cross_validate(pipe_nb2, X_train, y_train, return_train_score=True)\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d9bd06c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       0.99      1.00      1.00       978\n",
      "         eng       1.00      0.99      0.99      1002\n",
      "         nbl       0.99      0.99      0.99       952\n",
      "         nso       1.00      1.00      1.00      1023\n",
      "         sot       1.00      1.00      1.00      1019\n",
      "         ssw       0.99      1.00      1.00       994\n",
      "         tsn       1.00      1.00      1.00       986\n",
      "         tso       1.00      1.00      1.00       952\n",
      "         ven       1.00      1.00      1.00      1034\n",
      "         xho       1.00      0.99      0.99      1013\n",
      "         zul       0.98      0.99      0.98       937\n",
      "\n",
      "    accuracy                           0.99     10890\n",
      "   macro avg       0.99      0.99      0.99     10890\n",
      "weighted avg       0.99      0.99      0.99     10890\n",
      "\n",
      "[[ 978    0    0    0    0    0    0    0    0    0    0]\n",
      " [   6  991    1    2    0    0    1    0    0    0    1]\n",
      " [   0    0  939    0    1    1    0    0    0    2    9]\n",
      " [   0    0    0 1021    1    0    1    0    0    0    0]\n",
      " [   0    0    0    0 1019    0    0    0    0    0    0]\n",
      " [   0    0    1    0    0  993    0    0    0    0    0]\n",
      " [   0    0    0    3    1    0  982    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0  952    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0 1034    0    0]\n",
      " [   0    0    4    0    0    0    0    0    0 1003    6]\n",
      " [   0    0    8    0    0    4    0    0    0    2  923]]\n",
      "0.9949494949494949\n",
      " \n",
      "...............................\n",
      "<class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      0.99      0.99       995\n",
      "         eng       1.00      0.97      0.99      1014\n",
      "         nbl       0.94      0.88      0.91      1022\n",
      "         nso       0.98      0.95      0.96      1053\n",
      "         sot       0.98      0.98      0.98      1027\n",
      "         ssw       0.96      0.96      0.96       993\n",
      "         tsn       0.94      0.96      0.95       963\n",
      "         tso       1.00      0.99      0.99       959\n",
      "         ven       1.00      0.99      1.00      1038\n",
      "         xho       0.92      0.95      0.94       974\n",
      "         zul       0.86      0.94      0.90       852\n",
      "\n",
      "    accuracy                           0.96     10890\n",
      "   macro avg       0.96      0.96      0.96     10890\n",
      "weighted avg       0.96      0.96      0.96     10890\n",
      "\n",
      "[[ 984    2    3    0    0    3    1    0    0    0    2]\n",
      " [   0  988    5    0    0    6    0    0    2    5    8]\n",
      " [   0    0  900    1    0   16    0    0    0   39   66]\n",
      " [   0    0    0 1003   11    1   35    0    0    2    1]\n",
      " [   0    0    0    8 1002    0   17    0    0    0    0]\n",
      " [   0    0    4    0    0  958    2    0    0    4   25]\n",
      " [   0    1    4   14    9    1  928    1    0    3    2]\n",
      " [   0    0    0    0    0    1    0  950    1    6    1]\n",
      " [   0    0    3    0    0    2    1    1 1031    0    0]\n",
      " [   0    0   10    0    0    4    0    0    0  929   31]\n",
      " [   0    0   24    0    0    6    0    0    0   19  803]]\n",
      "0.9619834710743802\n",
      " \n",
      "...............................\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       0.99      1.00      1.00       978\n",
      "         eng       1.00      0.99      0.99      1002\n",
      "         nbl       0.99      0.99      0.99       945\n",
      "         nso       1.00      1.00      1.00      1023\n",
      "         sot       1.00      1.00      1.00      1021\n",
      "         ssw       1.00      1.00      1.00       996\n",
      "         tsn       1.00      1.00      1.00       986\n",
      "         tso       1.00      1.00      1.00       952\n",
      "         ven       1.00      1.00      1.00      1034\n",
      "         xho       1.00      0.99      1.00      1010\n",
      "         zul       0.99      0.99      0.99       943\n",
      "\n",
      "    accuracy                           1.00     10890\n",
      "   macro avg       1.00      1.00      1.00     10890\n",
      "weighted avg       1.00      1.00      1.00     10890\n",
      "\n",
      "[[ 977    0    1    0    0    0    0    0    0    0    0]\n",
      " [   7  991    1    1    0    0    1    0    0    0    1]\n",
      " [   0    0  940    0    0    0    0    0    0    1    4]\n",
      " [   0    0    0 1022    1    0    0    0    0    0    0]\n",
      " [   0    0    0    1 1020    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0  996    0    0    0    0    0]\n",
      " [   0    0    0    2    1    0  983    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0  952    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0 1034    0    0]\n",
      " [   0    0    1    0    0    0    0    0    0 1004    5]\n",
      " [   0    0   10    0    0    2    0    0    0    2  929]]\n",
      "0.9961432506887052\n",
      " \n",
      "...............................\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      0.99      0.99       989\n",
      "         eng       0.99      0.90      0.95      1092\n",
      "         nbl       0.82      0.84      0.83       929\n",
      "         nso       0.96      0.98      0.97      1006\n",
      "         sot       0.97      0.99      0.98      1000\n",
      "         ssw       0.83      0.87      0.85       960\n",
      "         tsn       0.96      0.94      0.95      1010\n",
      "         tso       0.99      0.99      0.99       949\n",
      "         ven       0.99      0.98      0.98      1040\n",
      "         xho       0.84      0.90      0.87       937\n",
      "         zul       0.84      0.80      0.82       978\n",
      "\n",
      "    accuracy                           0.93     10890\n",
      "   macro avg       0.93      0.93      0.93     10890\n",
      "weighted avg       0.93      0.93      0.93     10890\n",
      "\n",
      "[[ 980    3    1    0    0    0    1    1    0    1    2]\n",
      " [   3  985   23    2    0   29    0    0    3   38    9]\n",
      " [   1    3  784    7    2   35    5    3    1   38   50]\n",
      " [   0    0    0  983    5    0   17    1    0    0    0]\n",
      " [   0    0    1    1  990    0    3    0    5    0    0]\n",
      " [   0    0   36    0    0  831    0    4    1   28   60]\n",
      " [   0    0    3   31   22    3  948    0    1    1    1]\n",
      " [   0    0    1    0    0    2    1  940    3    2    0]\n",
      " [   0    0    0    0    3    8    6    2 1020    1    0]\n",
      " [   0    0   45    1    0   10    2    1    0  846   32]\n",
      " [   0    0   59    1    0   80    1    0    0   52  785]]\n",
      "0.9267217630853994\n",
      " \n",
      "...............................\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      0.99      1.00       989\n",
      "         eng       1.00      0.94      0.97      1056\n",
      "         nbl       0.94      0.97      0.95       923\n",
      "         nso       0.99      1.00      1.00      1022\n",
      "         sot       1.00      1.00      1.00      1021\n",
      "         ssw       0.95      0.98      0.97       970\n",
      "         tsn       1.00      0.99      0.99       989\n",
      "         tso       1.00      1.00      1.00       952\n",
      "         ven       1.00      1.00      1.00      1034\n",
      "         xho       0.94      0.97      0.96       973\n",
      "         zul       0.95      0.92      0.93       961\n",
      "\n",
      "    accuracy                           0.98     10890\n",
      "   macro avg       0.98      0.98      0.98     10890\n",
      "weighted avg       0.98      0.98      0.98     10890\n",
      "\n",
      "[[ 982    1    1    0    0    0    1    0    0    2    2]\n",
      " [   2  989   12    0    0   16    0    0    0   28    9]\n",
      " [   0    1  894    0    0    6    0    0    0    8   14]\n",
      " [   0    0    0 1020    1    0    1    0    0    0    0]\n",
      " [   0    0    0    1 1019    0    1    0    0    0    0]\n",
      " [   0    0    8    0    0  950    0    0    0    2   10]\n",
      " [   0    0    0    5    2    0  981    0    0    1    0]\n",
      " [   0    0    0    0    0    0    0  952    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0 1034    0    0]\n",
      " [   0    0    9    0    0    0    0    0    0  948   16]\n",
      " [   0    0   29    0    0   26    0    0    0   18  888]]\n",
      "0.9786042240587696\n",
      " \n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    LogisticRegression, \n",
    "    KNeighborsClassifier,\n",
    "    SVC,\n",
    "    DecisionTreeClassifier,\n",
    "    RandomForestClassifier,    \n",
    "]\n",
    "predictions_list = []\n",
    "models_list =[]\n",
    "for classifier in classifiers:\n",
    "    pipeline2 = Pipeline([\n",
    "        ('bow',CountVectorizer(stop_words='english', \n",
    "                                 min_df=2, \n",
    "                                 max_df=0.5, \n",
    "                                 ngram_range=(1, 1))),  # strings to token integer counts\n",
    "        ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "        ('classifier', classifier()),  # train on TF-IDF vectors \n",
    "    ])\n",
    " \n",
    "    pipeline2.fit(X_train,y_train)\n",
    "    predictions = pipeline2.predict(X_test)\n",
    "    models_list.append(pipeline2)\n",
    "    predictions_list.append(predictions)\n",
    "    print('...............................')\n",
    "    print(classifier)\n",
    "    print(classification_report(predictions,y_test)) \n",
    "    print(confusion_matrix(predictions,y_test))\n",
    "    print(accuracy_score(predictions,y_test))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fec59f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers\n",
    "from sklearn.svm import NuSVC, SVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingCVClassifier # <- Here is our boy\n",
    "\n",
    "# Used to ignore warnings generated from StackingCVClassifier\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                              5. Good Ol' Classifiers                        #\n",
    "###############################################################################\n",
    "# Initializing Support Vector classifier\n",
    "classifier1 = SVC(C = 50, degree = 1, gamma = \"auto\", kernel = \"rbf\", probability = True)\n",
    "\n",
    "\n",
    "\n",
    "# Initialing Nu Support Vector classifier\n",
    "classifier3 = NuSVC(degree = 1, kernel = \"rbf\", nu = 0.25, probability = True)\n",
    "\n",
    "# Initializing Random Forest classifier\n",
    "classifier4 = RandomForestClassifier(n_estimators = 500, criterion = \"gini\", max_depth = 10,\n",
    "                                     max_features = \"auto\", min_samples_leaf = 0.005,\n",
    "                                     min_samples_split = 0.005, n_jobs = -1, random_state = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e72d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                             6. Stacking Classifier                          #\n",
    "###############################################################################\n",
    "# Initializing the StackingCV classifier\n",
    "sclf = StackingCVClassifier(classifiers = [classifier1, classifier3, classifier4],\n",
    "                            shuffle = False,\n",
    "                            use_probas = True,\n",
    "                            cv = 5,\n",
    "                            meta_classifier = SVC(probability = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37a8edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline4 = Pipeline([\n",
    "#     ('bow',CountVectorizer(stop_words='english', \n",
    "#                              min_df=2, \n",
    "#                              max_df=0.5, \n",
    "#                              ngram_range=(1, 1))),  # strings to token integer counts\n",
    "#     ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "#     ('classifier', sclf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2846281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###############################################################################\n",
    "# #                       7. Putting classifiers in a dictionary                #\n",
    "# ###############################################################################\n",
    "# # Create list to store classifiers\n",
    "# classified = {\"SVC\": classifier1,\n",
    "#                \"NuSVC\": classifier3,\n",
    "#                \"RF\": classifier4,\n",
    "#                \"Stack\": sclf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1b6183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sclf.fit(X_train, y_train)\n",
    "# y_pred = sclf.predict(X_test).astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb1a2d7",
   "metadata": {},
   "source": [
    "## Exporting to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6e5e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Make Kaggle Submission\n",
    "test = test_df['text']\n",
    "pipeline1.fit(X,y)\n",
    "y_pred = pipeline2.predict(test)\n",
    "\n",
    "submission = pd.DataFrame(y_pred, columns = ['lang_id'])\n",
    "submission['index'] = test_df ['index']\n",
    "submission = submission[['index','lang_id']]\n",
    "submission.to_csv('submission_pipeline4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a4e036b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_df['text']\n",
    "pipe_nb.fit(X,y)\n",
    "y_pred = pipe_nb.predict(test)\n",
    "\n",
    "submission = pd.DataFrame(y_pred, columns = ['lang_id'])\n",
    "submission['index'] = test_df ['index']\n",
    "submission = submission[['index','lang_id']]\n",
    "submission.to_csv('submission_pipeline9.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0b66a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "test = test_df['text']\n",
    "pipe_nb2.fit(X,y)\n",
    "y_pred = pipe_nb2.predict(test)\n",
    "\n",
    "submission = pd.DataFrame(y_pred, columns = ['lang_id'])\n",
    "submission['index'] = test_df ['index']\n",
    "submission = submission[['index','lang_id']]\n",
    "submission.to_csv('submission_pipeline6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de0b91c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
